---
title: |
    | VectorBiTE Methods Training
    | Introduction to Bayesian Computation and MCMC with JAGS
author: | 
    | The VectorBiTE Team
    | (Leah R. Johnson, Virginia Tech)
date: "Summer 2021"
output:
  beamer_presentation:
    fig_caption: no
    includes:
      in_header: header.tex
    latex_engine: pdflatex
    slide_level: 2
    highlight: tango
    colortheme: "seagull"
    fonttheme: "structurebold"
    theme: "Szeged"
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = FALSE, 
                      echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE,
                      #fig.height=6, 
                      #fig.width = 1.777777*6,
                      tidy = FALSE, 
                      comment = NA, 
                      highlight = TRUE, 
                      prompt = FALSE, 
                      crop = TRUE,
                      comment = "#>",
                      collapse = TRUE)
library(knitr)
library(kableExtra)
library(xtable)
library(viridis)

options(stringsAsFactors=FALSE)
knit_hooks$set(no.main = function(before, options, envir) {
    if (before) par(mar = c(4.1, 4.1, 1.1, 1.1))  # smaller margin on top
})
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set(width = 60)
source("my_knitter.R")
#library(tidyverse)
#library(reshape2)
#theme_set(theme_light(base_size = 16))
make_latex_decorator <- function(output, otherwise) {
  function() {
      if (knitr:::is_latex_output()) output else otherwise
  }
}
insert_pause <- make_latex_decorator(". . .", "\n")
insert_slide_break <- make_latex_decorator("----", "\n")
insert_inc_bullet <- make_latex_decorator("> *", "*")
insert_html_math <- make_latex_decorator("", "$$")
## classoption: aspectratio=169
```



## Learning Objectives

 
1. Understand the basic principles underlying Bayesian modeling methodology
1.  Introduce how to use Bayesian inference for real-world problems
1. Introduce computation tools to perform inference for simple models in R (how to turn the Bayesian crank)
1. Appreciate the need for sensitivity analysis, model checking and comparison, and the potential dangers of Bayesian methods.
 

  


 
##  Numerical Methods

Most of the time we can't get a nice analytic form for a posterior distribution. If we go back to the full Bayes theorem:
$$
\text{Pr}(\theta|Y) = \frac{\mathcal{L}(\theta; Y)f(\theta)}{\text{Pr}(Y)}
$$
We are usually specifying the likelihood and the prior but we often don't know the normalizing constant in the denominator. Without this, the probabilities don't properly integrate to 1 and we  `r myred("can't make probability statements")`. We need a way to approximate the distribution. We'll use Monte Carlo methods. 
  



 
##  Stochastic Simulation/Computation

Stochastic simulation is a way to understand variability in a system and for calculating quantities that may be difficult or impossible to obtain directly. 

`r sk2()`

Monte Carlo (MC) methods are ``a broad class of computational algorithms that rely on  `r mygrn("repeated random sampling")` to obtain numerical results.'' - Wikipedia 



  


 
--------------------

___`r myred("How does it work?")`___

`r sk2()`
Run a simulation/computer calculation (with some component that is "random") many many times in order to obtain the distribution of an unknown probabilistic quantity.

\bigskip

A basic algorithm: 
 
1. Obtain random deviate(s) from a probability distribution
1. Make a calculation from your system
1. Record the result of the calculation to save it for later
1. Repeat many times
 

\vfill

  

 
-----------------

We typically have four reasons to use MC
 
1. Explore possible patterns/behaviors that a model can exhibit.
1. Create synthetic data to use in place of real data to test estimation procedures.
1. Estimate quantities that are difficult to calculate directly.
1. Understand and quantify uncertainty.
 
`r sk2()`

In our Bayesian analyses we're primarily leaning on MC for the 3rd point, but we get the last for free along with it. 


 
##  MC for Bayesian Statistics

We use Monte Carlo (MC) methods to generate random deviates in the right ratios from the target posterior called ___`r myblue("draws")`___ or samples. We then use these draws to approximate our distribution and make inference statements (estimates, CIs, etc). 

`r sk2()`
We can also use the draws to calculate the posterior distribution of `r mygrn("any function of our estimated parameters")`. As the number of draws/samples gets large we can approximate these quantities arbitrarily high precision.

  


 
##  The ``plug-in principle''

Using MC to perform these calculations (and to propagate the uncertainty) rests on the idea of the `r myred("plug-in principle")`: 

`r sk2()`

`r myblue("A summary statistic or other feature of a distribution  (e.g. expected value) can be approximated by the same summary/feature of an empirical sample from that distribution (e.g., sample mean).")` 

`r sk2()`

The approximation becomes more accurate if the number of samples is very large.
`r sk2()`

  


 
---------------

___`r myred("Example:")`___ Numerical 92\% CI of a normal distribution with mean $\mu$ and variance $\sigma^2$. 

`r sk2()`
Imagine we want to find, for some unknown reason, the central 92\% CI for a normal distribution.  How can we calculate this without using a look-up table, or similar function?

`r sk2()`
If we are able to generate samples from the desired distribution (which we'll take as given for now), we can use MC and the plug-in principle as follows:

--------
 
1. Generate many samples from the target distribution (say $N=2000$, to get good estimates).  
1. Find the $\alpha/2$ and $1-\alpha/2$ empirical quantiles (here 4\% and 96\%). For example these can be approximated by the $N \times \left( \frac{\alpha}{2} , 1-\frac{\alpha}{2} \right)$ order statistics.
1. You're done.

`r sk2()`
 
```{r echo=TRUE}
alpha<-0.04; N<-2000
x<-rbeta(N, 2, 20) ## take samples
o<-order(x) ## order them
o[c(N*alpha/2, N*(1-(alpha/2)))] ## take the appropriate samples
```

  



 
##  Markov Chain MC (MCMC)

The most commonly used numerical algorithm for generating posterior samples is MCMC.  

`r sk1()`
A  `r myblue("Markov Chain")` is a randomly generated sequence of numbers where each draw depends on the one immediately preceding it.

`r sk1()`


```{r, fig.align='center', out.width="60%"}
include_graphics("MCMC.jpg")
```

\vfill
\hfill {\tiny Plot -- Ian Murray (http://mlg.eng.cam.ac.uk/zoubin/tut06/mcmc.pdf)} 
  

 
##  Gibbs Sampling

One specific algorithm that is commonly used is  `r myblue("Gibbs Sampling")`.  

`r sk2()`
Gibbs sampling leverages the _`r mygrn("conditional")`_ distributions of parameters to generate samples by proposing them one at a time. This is the algorithm implemented in the popular Bayesian packages BUGS, WinBUGS, and JAGS/${\tt rjags}$. 

`r sk2()` 
We will treat Gibbs sampling and other of the numerical methods as mostly "black boxes". We'll learn to diagnose output from these later on in the practical component.


  


 
##  What do we do with Posterior Samples?

We can treat the draws much like we would data:

`r sk1()`
 
-  Calculate posterior summaries (mean, median, mode, etc) just like we would a data sample
-  Calculate precision of the summaries (e.g., sample variance)
-  CIs via quantiles (order statistics of the data) or HPD intervals (using ${\tt CODA}$ package in ${\tt R}$)
 
`r sk1()`

If the samples are parameters in a complex model, we can plug them all in, one at a time, to get a range of possible predictions from the model (we'll see this in the practical bit, later on). 

  

 
##  How do we compare models?

The simplest way that we will use to compare models is via the  `r myblue(" Deviance Information Criterion")` (DIC). Like AIC and BIC, DIC seeks to judge a model on how well it fits, penalized by the complexity of the model.
$$
DIC = D(\bar{\theta}) + 2p_D
$$
where:
 
-  Deviance: $D(\theta)=-2\log(\mathcal{L}(\theta; y)) + C$
-  Penalty: $p_D = \bar{D} -D(\bar{\theta})$
-  $D(\bar{\theta})$: deviance at the posterior mean of $\theta$
-  $\bar{D}$: average deviance across the posterior samples.

`r sk1()`
 
 \hfill $\rightarrow$ `r myred("Already implemented in JAGS!")`
  


 
##  Bayesian using JAGS

JAGS implements a version of Gibbs sampling in a fairly easy to use package.  

`r sk2()`


That is, once you specify the appropriate  __`r myblue("sampling distribution/likelihood")`__ and any  __`r myred("priors")`__ for the parameters, it will use MCMC to obtain samples from the posterior in the right ratios so that we can calculate whatever we want.


  


 
##  Specifying models in JAGS  

The trickiest and most important part of each analysis is properly specifying the model for all of the data that you want to fit. Before you begin to code, you need to decide:

`r sk1()`
 
- What is the relationship between your predictors and your response?
- What kind of probability distribution should you use to describe your response variable?
- Are there any constraints on your parameters or responses that you need to encode in your prior or likelihood, respectively?
 

  

 
##  Next Steps

There is one longish practical focusing on using JAGS/${\tt rjags}$ to conduct a analysis. It has two main chuncks: 

`r sk1()`

1. Comparing your conjugate Bayesian analysis on the midge data to the approximate results with JAGS, and expanding by estimating the variance. 
1. Fitting the Aedes trait data and fit a TPC to the data using JAGS. 

`r sk1()`

For both you'll also be led through visualizing your MCMC chains and your posterior distributions of parameters and predictions.   

